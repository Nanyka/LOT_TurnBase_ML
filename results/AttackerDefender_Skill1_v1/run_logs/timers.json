{
    "name": "root",
    "gauges": {
        "Defender.Policy.Entropy.mean": {
            "value": 1.2947494983673096,
            "min": 1.1114698648452759,
            "max": 1.3027416467666626,
            "count": 54
        },
        "Defender.Policy.Entropy.sum": {
            "value": 12895.705078125,
            "min": 198.54623413085938,
            "max": 92543.7578125,
            "count": 54
        },
        "Defender.Environment.EpisodeLength.mean": {
            "value": 22.624113475177303,
            "min": 13.0,
            "max": 23.42439024390244,
            "count": 54
        },
        "Defender.Environment.EpisodeLength.sum": {
            "value": 9570.0,
            "min": 13.0,
            "max": 72601.0,
            "count": 54
        },
        "Defender.IsTraining.mean": {
            "value": 1.0,
            "min": 1.0,
            "max": 1.0,
            "count": 54
        },
        "Defender.IsTraining.sum": {
            "value": 1.0,
            "min": 1.0,
            "max": 1.0,
            "count": 54
        },
        "Defender.Step.mean": {
            "value": 1529997.0,
            "min": 1009989.0,
            "max": 1529997.0,
            "count": 53
        },
        "Defender.Step.sum": {
            "value": 1529997.0,
            "min": 1009989.0,
            "max": 1529997.0,
            "count": 53
        },
        "Defender.Policy.ExtrinsicBaselineEstimate.mean": {
            "value": -0.4865051805973053,
            "min": -1.6930608749389648,
            "max": -0.4865051805973053,
            "count": 53
        },
        "Defender.Policy.ExtrinsicBaselineEstimate.sum": {
            "value": -206.2781982421875,
            "min": -925.9417724609375,
            "max": -205.90426635742188,
            "count": 53
        },
        "Defender.Policy.ExtrinsicValueEstimate.mean": {
            "value": -0.4865051805973053,
            "min": -1.6930608749389648,
            "max": -0.4865051805973053,
            "count": 53
        },
        "Defender.Policy.ExtrinsicValueEstimate.sum": {
            "value": -206.2781982421875,
            "min": -925.9417724609375,
            "max": -205.90426635742188,
            "count": 53
        },
        "Defender.Environment.CumulativeReward.mean": {
            "value": 0.0,
            "min": 0.0,
            "max": 0.0,
            "count": 53
        },
        "Defender.Environment.CumulativeReward.sum": {
            "value": 0.0,
            "min": 0.0,
            "max": 0.0,
            "count": 53
        },
        "Defender.Policy.ExtrinsicReward.mean": {
            "value": -0.010462270733320489,
            "min": -0.7067196084145816,
            "max": 0.07469267670701189,
            "count": 53
        },
        "Defender.Policy.ExtrinsicReward.sum": {
            "value": -4.436002790927887,
            "min": -453.7139886021614,
            "max": 30.623997449874878,
            "count": 53
        },
        "Defender.Environment.GroupCumulativeReward.mean": {
            "value": -0.010462270733320489,
            "min": -0.7067196084145816,
            "max": 0.07469267670701189,
            "count": 53
        },
        "Defender.Environment.GroupCumulativeReward.sum": {
            "value": -4.436002790927887,
            "min": -453.7139886021614,
            "max": 30.623997449874878,
            "count": 53
        },
        "Defender.Losses.PolicyLoss.mean": {
            "value": 0.017124149234344563,
            "min": 0.009648369640732806,
            "max": 0.02207675304962322,
            "count": 25
        },
        "Defender.Losses.PolicyLoss.sum": {
            "value": 0.017124149234344563,
            "min": 0.009648369640732806,
            "max": 0.02207675304962322,
            "count": 25
        },
        "Defender.Losses.ValueLoss.mean": {
            "value": 0.046949928253889085,
            "min": 0.026403794003029665,
            "max": 0.1580001210172971,
            "count": 25
        },
        "Defender.Losses.ValueLoss.sum": {
            "value": 0.046949928253889085,
            "min": 0.026403794003029665,
            "max": 0.1580001210172971,
            "count": 25
        },
        "Defender.Losses.BaselineLoss.mean": {
            "value": 0.04700227690239747,
            "min": 0.026411824735502402,
            "max": 0.16111960311730703,
            "count": 25
        },
        "Defender.Losses.BaselineLoss.sum": {
            "value": 0.04700227690239747,
            "min": 0.026411824735502402,
            "max": 0.16111960311730703,
            "count": 25
        },
        "Defender.Policy.LearningRate.mean": {
            "value": 0.0003,
            "min": 0.0003,
            "max": 0.0003,
            "count": 25
        },
        "Defender.Policy.LearningRate.sum": {
            "value": 0.0003,
            "min": 0.0003,
            "max": 0.0003,
            "count": 25
        },
        "Defender.Policy.Epsilon.mean": {
            "value": 0.20000000000000007,
            "min": 0.20000000000000007,
            "max": 0.20000000000000007,
            "count": 25
        },
        "Defender.Policy.Epsilon.sum": {
            "value": 0.20000000000000007,
            "min": 0.20000000000000007,
            "max": 0.20000000000000007,
            "count": 25
        },
        "Defender.Policy.Beta.mean": {
            "value": 0.005000000000000001,
            "min": 0.005000000000000001,
            "max": 0.005000000000000001,
            "count": 25
        },
        "Defender.Policy.Beta.sum": {
            "value": 0.005000000000000001,
            "min": 0.005000000000000001,
            "max": 0.005000000000000001,
            "count": 25
        },
        "Attacker.Policy.Entropy.mean": {
            "value": 1.0084234476089478,
            "min": 0.973625659942627,
            "max": 1.1334645748138428,
            "count": 41
        },
        "Attacker.Policy.Entropy.sum": {
            "value": 10223.3974609375,
            "min": 9591.1865234375,
            "max": 677357.125,
            "count": 41
        },
        "Attacker.Environment.EpisodeLength.mean": {
            "value": 14.291858678955453,
            "min": 13.423188405797102,
            "max": 21.98135198135198,
            "count": 41
        },
        "Attacker.Environment.EpisodeLength.sum": {
            "value": 9304.0,
            "min": 9262.0,
            "max": 581071.0,
            "count": 41
        },
        "Attacker.Step.mean": {
            "value": 1399993.0,
            "min": 999998.0,
            "max": 1399993.0,
            "count": 41
        },
        "Attacker.Step.sum": {
            "value": 1399993.0,
            "min": 999998.0,
            "max": 1399993.0,
            "count": 41
        },
        "Attacker.Policy.ExtrinsicBaselineEstimate.mean": {
            "value": 0.5511565208435059,
            "min": 0.14349384605884552,
            "max": 0.9208588004112244,
            "count": 41
        },
        "Attacker.Policy.ExtrinsicBaselineEstimate.sum": {
            "value": 361.0075378417969,
            "min": 0.49953266978263855,
            "max": 632.6300048828125,
            "count": 41
        },
        "Attacker.Policy.ExtrinsicValueEstimate.mean": {
            "value": 0.5581703186035156,
            "min": 0.13599441945552826,
            "max": 0.9130220413208008,
            "count": 41
        },
        "Attacker.Policy.ExtrinsicValueEstimate.sum": {
            "value": 365.6015625,
            "min": 0.47676318883895874,
            "max": 630.51416015625,
            "count": 41
        },
        "Attacker.Environment.CumulativeReward.mean": {
            "value": 0.0,
            "min": 0.0,
            "max": 0.0,
            "count": 41
        },
        "Attacker.Environment.CumulativeReward.sum": {
            "value": 0.0,
            "min": 0.0,
            "max": 0.0,
            "count": 41
        },
        "Attacker.Policy.ExtrinsicReward.mean": {
            "value": 0.5884885350256476,
            "min": -0.2107448170925009,
            "max": 0.6712294204582555,
            "count": 41
        },
        "Attacker.Policy.ExtrinsicReward.sum": {
            "value": 385.45999044179916,
            "min": -91.67399543523788,
            "max": 465.1619883775711,
            "count": 41
        },
        "Attacker.Environment.GroupCumulativeReward.mean": {
            "value": 0.5884885350256476,
            "min": -0.2107448170925009,
            "max": 0.6712294204582555,
            "count": 41
        },
        "Attacker.Environment.GroupCumulativeReward.sum": {
            "value": 385.45999044179916,
            "min": -91.67399543523788,
            "max": 465.1619883775711,
            "count": 41
        },
        "Attacker.IsTraining.mean": {
            "value": 1.0,
            "min": 1.0,
            "max": 1.0,
            "count": 41
        },
        "Attacker.IsTraining.sum": {
            "value": 1.0,
            "min": 1.0,
            "max": 1.0,
            "count": 41
        },
        "Attacker.Losses.PolicyLoss.mean": {
            "value": 0.015468137773374717,
            "min": 0.011527711610930661,
            "max": 0.021410211718951664,
            "count": 19
        },
        "Attacker.Losses.PolicyLoss.sum": {
            "value": 0.015468137773374717,
            "min": 0.011527711610930661,
            "max": 0.021410211718951664,
            "count": 19
        },
        "Attacker.Losses.ValueLoss.mean": {
            "value": 0.12746419832110406,
            "min": 0.05889596864581108,
            "max": 0.12746419832110406,
            "count": 19
        },
        "Attacker.Losses.ValueLoss.sum": {
            "value": 0.12746419832110406,
            "min": 0.05889596864581108,
            "max": 0.12746419832110406,
            "count": 19
        },
        "Attacker.Losses.BaselineLoss.mean": {
            "value": 0.12883408268292745,
            "min": 0.05937874764204025,
            "max": 0.2937700072924296,
            "count": 19
        },
        "Attacker.Losses.BaselineLoss.sum": {
            "value": 0.12883408268292745,
            "min": 0.05937874764204025,
            "max": 0.2937700072924296,
            "count": 19
        },
        "Attacker.Policy.LearningRate.mean": {
            "value": 0.0003,
            "min": 0.0003,
            "max": 0.0003,
            "count": 19
        },
        "Attacker.Policy.LearningRate.sum": {
            "value": 0.0003,
            "min": 0.0003,
            "max": 0.0003,
            "count": 19
        },
        "Attacker.Policy.Epsilon.mean": {
            "value": 0.20000000000000007,
            "min": 0.20000000000000007,
            "max": 0.20000000000000007,
            "count": 19
        },
        "Attacker.Policy.Epsilon.sum": {
            "value": 0.20000000000000007,
            "min": 0.20000000000000007,
            "max": 0.20000000000000007,
            "count": 19
        },
        "Attacker.Policy.Beta.mean": {
            "value": 0.005000000000000001,
            "min": 0.005000000000000001,
            "max": 0.005000000000000001,
            "count": 19
        },
        "Attacker.Policy.Beta.sum": {
            "value": 0.005000000000000001,
            "min": 0.005000000000000001,
            "max": 0.005000000000000001,
            "count": 19
        }
    },
    "metadata": {
        "timer_format_version": "0.1.0",
        "start_time_seconds": "1681367198",
        "python_version": "3.9.13 (main, Oct 13 2022, 16:12:30) \n[Clang 12.0.0 ]",
        "command_line_arguments": "/Users/admin/opt/anaconda3/envs/my_rl_env/bin/mlagents-learn /Users/admin/Desktop/GameProjects/TestMLAgents/config/attackerdefender_skill1_v2.yaml --env=/Users/admin/Desktop/AttackerDefender_Skill1_v1.app --run-id=AttackerDefender_Skill1_v1 --no-graphic --resume",
        "mlagents_version": "0.30.0",
        "mlagents_envs_version": "0.30.0",
        "communication_protocol_version": "1.5.0",
        "pytorch_version": "1.11.0",
        "numpy_version": "1.21.2",
        "end_time_seconds": "1681371811"
    },
    "total": 4612.5982754940005,
    "count": 1,
    "self": 0.37663196599987714,
    "children": {
        "run_training.setup": {
            "total": 0.02740073799999987,
            "count": 1,
            "self": 0.02740073799999987
        },
        "TrainerController.start_learning": {
            "total": 4612.19424279,
            "count": 1,
            "self": 2.390231695057082,
            "children": {
                "TrainerController._reset_env": {
                    "total": 1.9317856859996725,
                    "count": 7,
                    "self": 1.9317856859996725
                },
                "TrainerController.advance": {
                    "total": 4607.568012999943,
                    "count": 111785,
                    "self": 2.850893684926632,
                    "children": {
                        "env_step": {
                            "total": 3097.785621160983,
                            "count": 111785,
                            "self": 2858.8420817740316,
                            "children": {
                                "SubprocessEnvManager._take_step": {
                                    "total": 237.00140061997018,
                                    "count": 111785,
                                    "self": 8.944874912891095,
                                    "children": {
                                        "TorchPolicy.evaluate": {
                                            "total": 228.0565257070791,
                                            "count": 165162,
                                            "self": 228.0565257070791
                                        }
                                    }
                                },
                                "workers": {
                                    "total": 1.942138766980921,
                                    "count": 111784,
                                    "self": 0.0,
                                    "children": {
                                        "worker_root": {
                                            "total": 4606.222654104057,
                                            "count": 111784,
                                            "is_parallel": true,
                                            "self": 2004.310339088047,
                                            "children": {
                                                "steps_from_proto": {
                                                    "total": 0.061767615999424264,
                                                    "count": 13,
                                                    "is_parallel": true,
                                                    "self": 0.002020847999300024,
                                                    "children": {
                                                        "_process_maybe_compressed_observation": {
                                                            "total": 0.05974676800012424,
                                                            "count": 26,
                                                            "is_parallel": true,
                                                            "self": 0.002039739000797569,
                                                            "children": {
                                                                "_observation_to_np_array": {
                                                                    "total": 0.05770702899932667,
                                                                    "count": 178,
                                                                    "is_parallel": true,
                                                                    "self": 0.002017292001304627,
                                                                    "children": {
                                                                        "process_pixels": {
                                                                            "total": 0.055689736998022044,
                                                                            "count": 178,
                                                                            "is_parallel": true,
                                                                            "self": 0.012440740001074868,
                                                                            "children": {
                                                                                "image_decompress": {
                                                                                    "total": 0.043248996996947175,
                                                                                    "count": 356,
                                                                                    "is_parallel": true,
                                                                                    "self": 0.043248996996947175
                                                                                }
                                                                            }
                                                                        }
                                                                    }
                                                                }
                                                            }
                                                        }
                                                    }
                                                },
                                                "UnityEnvironment.step": {
                                                    "total": 2601.850547400011,
                                                    "count": 111784,
                                                    "is_parallel": true,
                                                    "self": 21.84158111210172,
                                                    "children": {
                                                        "UnityEnvironment._generate_step_input": {
                                                            "total": 32.33513625612727,
                                                            "count": 111784,
                                                            "is_parallel": true,
                                                            "self": 32.33513625612727
                                                        },
                                                        "communicator.exchange": {
                                                            "total": 1868.2242611760678,
                                                            "count": 111784,
                                                            "is_parallel": true,
                                                            "self": 1868.2242611760678
                                                        },
                                                        "steps_from_proto": {
                                                            "total": 679.449568855714,
                                                            "count": 223567,
                                                            "is_parallel": true,
                                                            "self": 33.443274775645705,
                                                            "children": {
                                                                "_process_maybe_compressed_observation": {
                                                                    "total": 646.0062940800683,
                                                                    "count": 447134,
                                                                    "is_parallel": true,
                                                                    "self": 32.55918429022552,
                                                                    "children": {
                                                                        "_observation_to_np_array": {
                                                                            "total": 613.4471097898428,
                                                                            "count": 2808603,
                                                                            "is_parallel": true,
                                                                            "self": 33.74139717168748,
                                                                            "children": {
                                                                                "process_pixels": {
                                                                                    "total": 579.7057126181553,
                                                                                    "count": 2808603,
                                                                                    "is_parallel": true,
                                                                                    "self": 204.8413628921407,
                                                                                    "children": {
                                                                                        "image_decompress": {
                                                                                            "total": 374.8643497260146,
                                                                                            "count": 5617206,
                                                                                            "is_parallel": true,
                                                                                            "self": 374.8643497260146
                                                                                        }
                                                                                    }
                                                                                }
                                                                            }
                                                                        }
                                                                    }
                                                                }
                                                            }
                                                        }
                                                    }
                                                }
                                            }
                                        }
                                    }
                                }
                            }
                        },
                        "trainer_advance": {
                            "total": 1506.9314981540335,
                            "count": 223567,
                            "self": 16.591085329981524,
                            "children": {
                                "process_trajectory": {
                                    "total": 378.27385708905354,
                                    "count": 223567,
                                    "self": 377.80929477805336,
                                    "children": {
                                        "RLTrainer._checkpoint": {
                                            "total": 0.4645623110001855,
                                            "count": 3,
                                            "self": 0.4645623110001855
                                        }
                                    }
                                },
                                "_update_policy": {
                                    "total": 1112.0665557349985,
                                    "count": 45,
                                    "self": 136.05535860500072,
                                    "children": {
                                        "TorchPOCAOptimizer.update": {
                                            "total": 976.0111971299978,
                                            "count": 1350,
                                            "self": 976.0111971299978
                                        }
                                    }
                                }
                            }
                        }
                    }
                },
                "trainer_threads": {
                    "total": 1.7830006981967017e-06,
                    "count": 1,
                    "self": 1.7830006981967017e-06
                },
                "TrainerController._save_models": {
                    "total": 0.3042106259999855,
                    "count": 1,
                    "self": 0.004916248000881751,
                    "children": {
                        "RLTrainer._checkpoint": {
                            "total": 0.29929437799910374,
                            "count": 2,
                            "self": 0.29929437799910374
                        }
                    }
                }
            }
        }
    }
}