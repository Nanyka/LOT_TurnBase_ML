{
    "name": "root",
    "gauges": {
        "Defender.Policy.Entropy.mean": {
            "value": 2.0335710048675537,
            "min": 1.907578706741333,
            "max": 2.0759921073913574,
            "count": 45
        },
        "Defender.Policy.Entropy.sum": {
            "value": 20254.3671875,
            "min": 5206.33251953125,
            "max": 148994.328125,
            "count": 45
        },
        "Defender.Environment.EpisodeLength.mean": {
            "value": 23.028846153846153,
            "min": 18.24097291875627,
            "max": 23.97,
            "count": 45
        },
        "Defender.Environment.EpisodeLength.sum": {
            "value": 9580.0,
            "min": 2348.0,
            "max": 72960.0,
            "count": 45
        },
        "Defender.Step.mean": {
            "value": 8989989.0,
            "min": 8549991.0,
            "max": 8989989.0,
            "count": 45
        },
        "Defender.Step.sum": {
            "value": 8989989.0,
            "min": 8549991.0,
            "max": 8989989.0,
            "count": 45
        },
        "Defender.Policy.ExtrinsicBaselineEstimate.mean": {
            "value": 0.45448556542396545,
            "min": 0.45448556542396545,
            "max": 0.5089584589004517,
            "count": 45
        },
        "Defender.Policy.ExtrinsicBaselineEstimate.sum": {
            "value": 189.0659942626953,
            "min": 50.451412200927734,
            "max": 220.70033264160156,
            "count": 45
        },
        "Defender.Policy.ExtrinsicValueEstimate.mean": {
            "value": 0.45448556542396545,
            "min": 0.45448556542396545,
            "max": 0.5089584589004517,
            "count": 45
        },
        "Defender.Policy.ExtrinsicValueEstimate.sum": {
            "value": 189.0659942626953,
            "min": 50.451412200927734,
            "max": 220.70033264160156,
            "count": 45
        },
        "Defender.Environment.CumulativeReward.mean": {
            "value": 0.0,
            "min": 0.0,
            "max": 0.0,
            "count": 45
        },
        "Defender.Environment.CumulativeReward.sum": {
            "value": 0.0,
            "min": 0.0,
            "max": 0.0,
            "count": 45
        },
        "Defender.Policy.ExtrinsicReward.mean": {
            "value": 0.07567307109443042,
            "min": -0.010446958428850022,
            "max": 0.14131999388337135,
            "count": 45
        },
        "Defender.Policy.ExtrinsicReward.sum": {
            "value": 31.47999757528305,
            "min": -4.62800258398056,
            "max": 56.62999749183655,
            "count": 45
        },
        "Defender.Environment.GroupCumulativeReward.mean": {
            "value": 0.07567307109443042,
            "min": -0.010446958428850022,
            "max": 0.14131999388337135,
            "count": 45
        },
        "Defender.Environment.GroupCumulativeReward.sum": {
            "value": 31.47999757528305,
            "min": -4.62800258398056,
            "max": 56.62999749183655,
            "count": 45
        },
        "Defender.IsTraining.mean": {
            "value": 1.0,
            "min": 1.0,
            "max": 1.0,
            "count": 45
        },
        "Defender.IsTraining.sum": {
            "value": 1.0,
            "min": 1.0,
            "max": 1.0,
            "count": 45
        },
        "Defender.Losses.PolicyLoss.mean": {
            "value": 0.014261882053688169,
            "min": 0.011830865091178566,
            "max": 0.020453113464949033,
            "count": 21
        },
        "Defender.Losses.PolicyLoss.sum": {
            "value": 0.014261882053688169,
            "min": 0.011830865091178566,
            "max": 0.020453113464949033,
            "count": 21
        },
        "Defender.Losses.ValueLoss.mean": {
            "value": 0.015974062277625004,
            "min": 0.0008861509670775073,
            "max": 0.022980877881248793,
            "count": 21
        },
        "Defender.Losses.ValueLoss.sum": {
            "value": 0.015974062277625004,
            "min": 0.0008861509670775073,
            "max": 0.022980877881248793,
            "count": 21
        },
        "Defender.Losses.BaselineLoss.mean": {
            "value": 0.015974062277625004,
            "min": 0.0008861509670775073,
            "max": 0.022980877881248793,
            "count": 21
        },
        "Defender.Losses.BaselineLoss.sum": {
            "value": 0.015974062277625004,
            "min": 0.0008861509670775073,
            "max": 0.022980877881248793,
            "count": 21
        },
        "Defender.Policy.LearningRate.mean": {
            "value": 0.0003,
            "min": 0.0003,
            "max": 0.0003,
            "count": 21
        },
        "Defender.Policy.LearningRate.sum": {
            "value": 0.0003,
            "min": 0.0003,
            "max": 0.0003,
            "count": 21
        },
        "Defender.Policy.Epsilon.mean": {
            "value": 0.20000000000000007,
            "min": 0.20000000000000007,
            "max": 0.20000000000000007,
            "count": 21
        },
        "Defender.Policy.Epsilon.sum": {
            "value": 0.20000000000000007,
            "min": 0.20000000000000007,
            "max": 0.20000000000000007,
            "count": 21
        },
        "Defender.Policy.Beta.mean": {
            "value": 0.005000000000000001,
            "min": 0.005000000000000001,
            "max": 0.005000000000000001,
            "count": 21
        },
        "Defender.Policy.Beta.sum": {
            "value": 0.005000000000000001,
            "min": 0.005000000000000001,
            "max": 0.005000000000000001,
            "count": 21
        },
        "Attacker.Policy.Entropy.mean": {
            "value": 1.5210113525390625,
            "min": 1.2820852994918823,
            "max": 1.5943537950515747,
            "count": 40
        },
        "Attacker.Policy.Entropy.sum": {
            "value": 15804.8291015625,
            "min": 13088.80859375,
            "max": 952405.75,
            "count": 40
        },
        "Attacker.Environment.EpisodeLength.mean": {
            "value": 17.333333333333332,
            "min": 9.644654088050315,
            "max": 23.875621890547265,
            "count": 40
        },
        "Attacker.Environment.EpisodeLength.sum": {
            "value": 9516.0,
            "min": 9201.0,
            "max": 584059.0,
            "count": 40
        },
        "Attacker.Step.mean": {
            "value": 8499996.0,
            "min": 8109992.0,
            "max": 8499996.0,
            "count": 40
        },
        "Attacker.Step.sum": {
            "value": 8499996.0,
            "min": 8109992.0,
            "max": 8499996.0,
            "count": 40
        },
        "Attacker.Policy.ExtrinsicBaselineEstimate.mean": {
            "value": 0.04722004383802414,
            "min": -0.5795190334320068,
            "max": 0.12168344110250473,
            "count": 40
        },
        "Attacker.Policy.ExtrinsicBaselineEstimate.sum": {
            "value": 25.829364776611328,
            "min": -326.87701416015625,
            "max": 87.04772186279297,
            "count": 40
        },
        "Attacker.Policy.ExtrinsicValueEstimate.mean": {
            "value": 0.08161512017250061,
            "min": -0.5781923532485962,
            "max": 0.1686338633298874,
            "count": 40
        },
        "Attacker.Policy.ExtrinsicValueEstimate.sum": {
            "value": 44.643470764160156,
            "min": -321.64691162109375,
            "max": 109.61201477050781,
            "count": 40
        },
        "Attacker.Environment.CumulativeReward.mean": {
            "value": 0.0,
            "min": 0.0,
            "max": 0.0,
            "count": 40
        },
        "Attacker.Environment.CumulativeReward.sum": {
            "value": 0.0,
            "min": 0.0,
            "max": 0.0,
            "count": 40
        },
        "Attacker.Policy.ExtrinsicReward.mean": {
            "value": 0.08263986790637866,
            "min": -0.4231343106992209,
            "max": 0.6281898927085007,
            "count": 40
        },
        "Attacker.Policy.ExtrinsicReward.sum": {
            "value": 45.20400774478912,
            "min": -170.38199284672737,
            "max": 595.5240182876587,
            "count": 40
        },
        "Attacker.Environment.GroupCumulativeReward.mean": {
            "value": 0.08263986790637866,
            "min": -0.4231343106992209,
            "max": 0.6281898927085007,
            "count": 40
        },
        "Attacker.Environment.GroupCumulativeReward.sum": {
            "value": 45.20400774478912,
            "min": -170.38199284672737,
            "max": 595.5240182876587,
            "count": 40
        },
        "Attacker.IsTraining.mean": {
            "value": 1.0,
            "min": 1.0,
            "max": 1.0,
            "count": 40
        },
        "Attacker.IsTraining.sum": {
            "value": 1.0,
            "min": 1.0,
            "max": 1.0,
            "count": 40
        },
        "Attacker.Losses.PolicyLoss.mean": {
            "value": 0.02037952276878059,
            "min": 0.013191871934880813,
            "max": 0.02037952276878059,
            "count": 19
        },
        "Attacker.Losses.PolicyLoss.sum": {
            "value": 0.02037952276878059,
            "min": 0.013191871934880813,
            "max": 0.02037952276878059,
            "count": 19
        },
        "Attacker.Losses.ValueLoss.mean": {
            "value": 0.14295808722575506,
            "min": 0.008606855625597138,
            "max": 0.16686389843622842,
            "count": 19
        },
        "Attacker.Losses.ValueLoss.sum": {
            "value": 0.14295808722575506,
            "min": 0.008606855625597138,
            "max": 0.16686389843622842,
            "count": 19
        },
        "Attacker.Losses.BaselineLoss.mean": {
            "value": 0.1458477055033048,
            "min": 0.008798946347087621,
            "max": 0.18370543370644252,
            "count": 19
        },
        "Attacker.Losses.BaselineLoss.sum": {
            "value": 0.1458477055033048,
            "min": 0.008798946347087621,
            "max": 0.18370543370644252,
            "count": 19
        },
        "Attacker.Policy.LearningRate.mean": {
            "value": 0.0003,
            "min": 0.0003,
            "max": 0.0003,
            "count": 19
        },
        "Attacker.Policy.LearningRate.sum": {
            "value": 0.0003,
            "min": 0.0003,
            "max": 0.0003,
            "count": 19
        },
        "Attacker.Policy.Epsilon.mean": {
            "value": 0.20000000000000007,
            "min": 0.20000000000000007,
            "max": 0.20000000000000007,
            "count": 19
        },
        "Attacker.Policy.Epsilon.sum": {
            "value": 0.20000000000000007,
            "min": 0.20000000000000007,
            "max": 0.20000000000000007,
            "count": 19
        },
        "Attacker.Policy.Beta.mean": {
            "value": 0.005000000000000001,
            "min": 0.005000000000000001,
            "max": 0.005000000000000001,
            "count": 19
        },
        "Attacker.Policy.Beta.sum": {
            "value": 0.005000000000000001,
            "min": 0.005000000000000001,
            "max": 0.005000000000000001,
            "count": 19
        }
    },
    "metadata": {
        "timer_format_version": "0.1.0",
        "start_time_seconds": "1682221712",
        "python_version": "3.9.13 (main, Oct 13 2022, 16:12:30) \n[Clang 12.0.0 ]",
        "command_line_arguments": "/Users/admin/opt/anaconda3/envs/my_rl_env/bin/mlagents-learn /Users/admin/Desktop/GameProjects/TestMLAgents/config/attackerdefender_skill1_v2.yaml --env=/Users/admin/Desktop/AttackerDefender_Skill1_v1.app --run-id=AttackerDefender_Skill1_v2 --no-graphic --resume",
        "mlagents_version": "0.30.0",
        "mlagents_envs_version": "0.30.0",
        "communication_protocol_version": "1.5.0",
        "pytorch_version": "1.11.0",
        "numpy_version": "1.21.2",
        "end_time_seconds": "1682225752"
    },
    "total": 4040.9579843740003,
    "count": 1,
    "self": 0.16691522300016004,
    "children": {
        "run_training.setup": {
            "total": 0.027513805999999974,
            "count": 1,
            "self": 0.027513805999999974
        },
        "TrainerController.start_learning": {
            "total": 4040.763555345,
            "count": 1,
            "self": 1.8879204080099043,
            "children": {
                "TrainerController._reset_env": {
                    "total": 2.020936838999891,
                    "count": 7,
                    "self": 2.020936838999891
                },
                "TrainerController.advance": {
                    "total": 4036.57944257599,
                    "count": 96770,
                    "self": 2.2863940550050756,
                    "children": {
                        "env_step": {
                            "total": 2555.3039839990242,
                            "count": 96770,
                            "self": 2362.5864968060146,
                            "children": {
                                "SubprocessEnvManager._take_step": {
                                    "total": 191.12841516499907,
                                    "count": 96770,
                                    "self": 6.911422770031322,
                                    "children": {
                                        "TorchPolicy.evaluate": {
                                            "total": 184.21699239496775,
                                            "count": 143112,
                                            "self": 184.21699239496775
                                        }
                                    }
                                },
                                "workers": {
                                    "total": 1.5890720280106834,
                                    "count": 96769,
                                    "self": 0.0,
                                    "children": {
                                        "worker_root": {
                                            "total": 4035.3994062730253,
                                            "count": 96769,
                                            "is_parallel": true,
                                            "self": 1884.178955650039,
                                            "children": {
                                                "steps_from_proto": {
                                                    "total": 0.06211250900008336,
                                                    "count": 13,
                                                    "is_parallel": true,
                                                    "self": 0.0020046369996644664,
                                                    "children": {
                                                        "_process_maybe_compressed_observation": {
                                                            "total": 0.060107872000418894,
                                                            "count": 26,
                                                            "is_parallel": true,
                                                            "self": 0.0019325890025649883,
                                                            "children": {
                                                                "_observation_to_np_array": {
                                                                    "total": 0.058175282997853905,
                                                                    "count": 178,
                                                                    "is_parallel": true,
                                                                    "self": 0.0018698319962067167,
                                                                    "children": {
                                                                        "process_pixels": {
                                                                            "total": 0.05630545100164719,
                                                                            "count": 178,
                                                                            "is_parallel": true,
                                                                            "self": 0.011966658001693053,
                                                                            "children": {
                                                                                "image_decompress": {
                                                                                    "total": 0.044338792999954135,
                                                                                    "count": 356,
                                                                                    "is_parallel": true,
                                                                                    "self": 0.044338792999954135
                                                                                }
                                                                            }
                                                                        }
                                                                    }
                                                                }
                                                            }
                                                        }
                                                    }
                                                },
                                                "UnityEnvironment.step": {
                                                    "total": 2151.1583381139862,
                                                    "count": 96769,
                                                    "is_parallel": true,
                                                    "self": 18.1190772950099,
                                                    "children": {
                                                        "UnityEnvironment._generate_step_input": {
                                                            "total": 26.822336629991874,
                                                            "count": 96769,
                                                            "is_parallel": true,
                                                            "self": 26.822336629991874
                                                        },
                                                        "communicator.exchange": {
                                                            "total": 1569.0014771440399,
                                                            "count": 96769,
                                                            "is_parallel": true,
                                                            "self": 1569.0014771440399
                                                        },
                                                        "steps_from_proto": {
                                                            "total": 537.2154470449444,
                                                            "count": 193537,
                                                            "is_parallel": true,
                                                            "self": 26.94657324796077,
                                                            "children": {
                                                                "_process_maybe_compressed_observation": {
                                                                    "total": 510.26887379698366,
                                                                    "count": 387074,
                                                                    "is_parallel": true,
                                                                    "self": 25.78834993108569,
                                                                    "children": {
                                                                        "_observation_to_np_array": {
                                                                            "total": 484.48052386589796,
                                                                            "count": 2421116,
                                                                            "is_parallel": true,
                                                                            "self": 26.477769619827882,
                                                                            "children": {
                                                                                "process_pixels": {
                                                                                    "total": 458.0027542460701,
                                                                                    "count": 2421116,
                                                                                    "is_parallel": true,
                                                                                    "self": 161.24289021366536,
                                                                                    "children": {
                                                                                        "image_decompress": {
                                                                                            "total": 296.7598640324047,
                                                                                            "count": 4842232,
                                                                                            "is_parallel": true,
                                                                                            "self": 296.7598640324047
                                                                                        }
                                                                                    }
                                                                                }
                                                                            }
                                                                        }
                                                                    }
                                                                }
                                                            }
                                                        }
                                                    }
                                                }
                                            }
                                        }
                                    }
                                }
                            }
                        },
                        "trainer_advance": {
                            "total": 1478.9890645219607,
                            "count": 193537,
                            "self": 12.940390163953452,
                            "children": {
                                "process_trajectory": {
                                    "total": 315.6535288660052,
                                    "count": 193537,
                                    "self": 315.47793321200515,
                                    "children": {
                                        "RLTrainer._checkpoint": {
                                            "total": 0.1755956540000625,
                                            "count": 1,
                                            "self": 0.1755956540000625
                                        }
                                    }
                                },
                                "_update_policy": {
                                    "total": 1150.395145492002,
                                    "count": 40,
                                    "self": 114.90012125800513,
                                    "children": {
                                        "TorchPOCAOptimizer.update": {
                                            "total": 1035.495024233997,
                                            "count": 1200,
                                            "self": 1035.495024233997
                                        }
                                    }
                                }
                            }
                        }
                    }
                },
                "trainer_threads": {
                    "total": 1.4419997569348197e-06,
                    "count": 1,
                    "self": 1.4419997569348197e-06
                },
                "TrainerController._save_models": {
                    "total": 0.27525408000019524,
                    "count": 1,
                    "self": 0.0014426970005843032,
                    "children": {
                        "RLTrainer._checkpoint": {
                            "total": 0.27381138299961094,
                            "count": 2,
                            "self": 0.27381138299961094
                        }
                    }
                }
            }
        }
    }
}